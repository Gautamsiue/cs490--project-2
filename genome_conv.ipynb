{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import mod_seqs, FileUtils, constants\n",
    "from SeqsData import SeqsData\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if GPU is available or else default to CPU usage.\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in test, train, and validation files\n",
      "Splitting the test, train and validation data into lists\n",
      "656590 2626360 172788\n",
      "One hot encoding 100% of the test data\n",
      "\n",
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "One hot encoding 100% of the train data\n",
      "\n",
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "One hot encoding 100% of the validation data\n",
      "\n",
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding \n",
    "\n",
    "print(\"Reading in test, train, and validation files\")\n",
    "test = FileUtils.readFile(constants.TEST) # which is 25% of data\n",
    "train = FileUtils.readFile(constants.TRAIN) # which is 70% of data\n",
    "validation = FileUtils.readFile(constants.VALID) # which is 5% of data\n",
    "\n",
    "print(\"Splitting the test, train and validation data into lists\")\n",
    "test = [line.split() for line in test]\n",
    "train = [line.split() for line in train]\n",
    "validation = [line.split() for line in validation]\n",
    "\n",
    "print(len(test), len(train), len(validation))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nDone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(656590, 2)\n"
     ]
    }
   ],
   "source": [
    "# create test dataset to be fed into the dataloader\n",
    "np.transpose(test_one_hot)\n",
    "print(test_one_hot.shape)\n",
    "sd_test = SeqsData(test_one_hot)\n",
    "\n",
    "# create train dataset to be fed into dataloader\n",
    "np.transpose(train_one_hot)\n",
    "sd_train = SeqsData(train_one_hot)\n",
    "\n",
    "# create train dataset to be fed into dataloader\n",
    "np.transpose(valid_one_hot)\n",
    "sd_valid = SeqsData(valid_one_hot)\n",
    "\n",
    "# DataLoader Objects are what feed the network the data by means of tensor stacks defined in the SeqsData class.\n",
    "test_dataloader = DataLoader(sd_test, batch_size=256, shuffle=True)\n",
    "train_dataloader = DataLoader(sd_train, batch_size=256, shuffle=True)\n",
    "valid_dataloader = DataLoader(sd_valid, batch_size=256, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class   GNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        # Layer1\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=96, kernel_size=11, stride=1, padding=1)\n",
    "    \n",
    "\n",
    "        # Layer2:\n",
    "        self.conv2 = nn.Conv1d(in_channels=96, out_channels=96, kernel_size=7, padding=1, stride=2) \n",
    "        self.local_response2=nn.LocalResponseNorm(size=5,alpha=0.0001,beta=0.75,k=2)\n",
    "\n",
    "        # Layer3:\n",
    "        self.conv3 = nn.Conv1d(in_channels=96, out_channels=96, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool_layer3 = nn.MaxPool1d(kernel_size=7, stride=2)\n",
    "        self.local_response = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
    "\n",
    "        # Layer4:\n",
    "        self.conv4 = nn.Conv1d(in_channels=96, out_channels=96, kernel_size=7, stride=4, padding=2)\n",
    "\n",
    "        # Layer5:\n",
    "        self.conv5=nn.Conv1d(in_channels=96, out_channels=96, kernel_size=1, stride=1)\n",
    "\n",
    "        # Layer6:\n",
    "        self.conv6=nn.Conv1d(in_channels=96, out_channels=96, kernel_size=1, stride=2)\n",
    "        self.pool_layer6=nn.MaxPool1d(kernel_size=1, stride=1) \n",
    "       \n",
    "        \n",
    "        # Layer7:\n",
    "        self.conv7=nn.Conv1d(in_channels=96, out_channels=96, kernel_size=3, stride=1, padding=1) \n",
    "\n",
    "        # Layer8:\n",
    "        self.conv8=nn.Conv1d(in_channels=96, out_channels=96, kernel_size=1, stride=1)\n",
    "\n",
    "        # Layer9:\n",
    "        self.conv9 = nn.Conv1d(in_channels=96, out_channels=96, kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        # Layer10:\n",
    "        self.fc1 = nn.Linear(in_features=(960), out_features=1024)\n",
    "        \n",
    "        # Layer11:\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=1024)\n",
    "             \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # applying ReLU to layer 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        # applying ReLU to layer 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "    \n",
    "        x = self.pool_layer3(F.relu(self.local_response(self.conv3(x))))\n",
    "        x = F.dropout(x, .5)\n",
    "\n",
    "        # applying ReLU to layer 4\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        # applying ReLU to layer 5\n",
    "        x = F.relu(self.conv5(x))\n",
    "\n",
    "        \n",
    "        # applying ReLU to layer 6\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.dropout(x, .5)\n",
    "\n",
    "        # applying ReLU to layer 7\n",
    "        x = F.relu(self.conv7(x))\n",
    "\n",
    "        # applying ReLU to layer 8\n",
    "        x = F.relu(self.conv8(x))\n",
    "\n",
    "        # applying ReLU to layer 9\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.dropout(x, .5)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flattening all Dimensions\n",
    "        \n",
    "        # applying ReLU to layer 10\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, .5)\n",
    "\n",
    "        # applying ReLU to layer 11\n",
    "        x = torch.ReLU(self.fc2(x))\n",
    "        # x = F.dropout(x, .5)\n",
    "\n",
    "    \n",
    "          \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # result size = ((size - kernelSize + 2 * padding) / stride) + 1\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(in_channels=4, out_channels=64, kernel_size=11) \n",
    "\n",
    "        self.pool2 = torch.nn.MaxPool1d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv1d(in_channels=64, out_channels=192, kernel_size=5, padding=2) \n",
    "\n",
    "        self.pool4 = torch.nn.MaxPool1d(kernel_size=3, stride=2)\n",
    "        self.conv5 = torch.nn.Conv1d(in_channels=192, out_channels=384, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv6 = torch.nn.Conv1d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv7 = torch.nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding=1) \n",
    "\n",
    "        self.pool8 = torch.nn.MaxPool1d(kernel_size=3, stride=2)\n",
    "        self.pool9 = torch.nn.AdaptiveAvgPool1d(6) \n",
    "        self.fc1 = torch.nn.Linear(in_features=(6 * 256), out_features=512)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(in_features=512, out_features=1024)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "\n",
    "        x = F.relu(self.conv6(x))\n",
    "\n",
    "        x = F.relu(self.conv7(x))\n",
    "\n",
    "        x = self.pool8(x)\n",
    "\n",
    "        x = self.pool9(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.dropout(x, 0.5)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = F.dropout(x, 0.5)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the model \n",
    "model = AlexNet()\n",
    "model.load_state_dict(torch.load(\"./alexnet.pth\"))\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(params=model.parameters(),lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTraining(model,device, train_dataloader, optimizer, epochs):\n",
    "    model.train()\n",
    "    for batch_ids, (seq, classes) in tqdm(enumerate(train_dataloader)):\n",
    "        classes=classes.type(torch.LongTensor)\n",
    "        seq, classes=seq.to(device), classes.to(device)\n",
    "        torch.autograd.set_detect_anomaly(True)     \n",
    "        optimizer.zero_grad()\n",
    "        output=model(seq)\n",
    "        loss = loss_fn(output,classes)            \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_dataloader):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for seq,classes in tqdm(test_dataloader):\n",
    "            seq,classes=seq.to(device), classes.to(device)\n",
    "            y_hat=model(seq)\n",
    "            test_loss+=F.nll_loss(y_hat,classes,reduction='sum').item()\n",
    "            _,y_pred=torch.max(y_hat,1)\n",
    "            correct+=(y_pred==classes).sum().item()\n",
    "    \n",
    "        test_loss/=len(test_dataloader)\n",
    "        print(\"\\n Test set: Average loss: {:.0f},Accuracy:{}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss,correct,len(test_dataloader.dataset),100.*correct/len(test_dataloader.dataset)))\n",
    "        print('*'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(preds, classes, tp=0, tn=0, fp=0, fn=0):\n",
    "    for pred, cl in zip(preds, classes):\n",
    "        if pred == 1 and cl == 1:\n",
    "            tp += 1\n",
    "        if pred == 0 and cl == 1:\n",
    "            fn += 1\n",
    "        if pred ==  1 and cl == 0:\n",
    "            fp += 1\n",
    "        if pred == 0 and cl == 0:\n",
    "            tn += 1\n",
    "    return tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef validation(model, device, valid_dataloader):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq,classes in valid_dataloader:\n",
    "            seq,classes=seq.to(device), classes.to(device)\n",
    "            y_hat=model(seq)\n",
    "            test_loss+=F.nll_loss(y_hat,classes, reduction='sum').item()\n",
    "            _,y_pred=torch.max(y_hat, 1)\n",
    "            correct+=(y_pred==classes).sum().item()\n",
    "            tp, tn, fp, fn = confusion_matrix(y_pred, classes, tp, tn, fp, fn)\n",
    "        test_loss/=len(valid_dataloader)\n",
    "        print(\"\\n Valid_set: Average loss: {:.0f},Accuracy:{}/{} ({:.0f}%)\\n\".format(\n",
    "                test_loss,correct,len(valid_dataloader.dataset),100.*correct/len(valid_dataloader.dataset)))\n",
    "        print('='*30)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"Actual no total: {tn + fp}, actual yes total: {fn + tp}\")\n",
    "    print(f\"n = {tp + tn + fp + fn}\")\n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "    print(f\"True positives: {tp}, True negatives: {tn}, False positives: {fp}, False negatives: {fn}\")\n",
    "    print(f\"Predicted no total: {tn + fn}, predicted yes total: {tp + fp}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1600248/2626360 (100%)]\tLoss: 0.140855\n",
      "\n",
      " Test set: Average loss: -1310,Accuracy:626382/656590 (65%)\n",
      "\n",
      "==============================\n",
      "\n",
      " Validation set: Average loss: -1321,Accuracy:168362/172788 (67%)\n",
      "\n",
      "==============================\n",
      "n = 172788\n",
      "True positives: 81867, True negatives: 75123, False positives: 2460, False negatives: 5783\n",
      "Actual no total: 87594, actual yes total: 86394\n",
      "Predicted no total: 89650, predicted yes total: 83138\n",
      "Precision: 0.9713488416849094, Recall: 0.934740838484154, F1 Score: 0.9526932968407145\n",
      "Train Epoch: 2 [1600248/2626360 (100%)]\tLoss: 0.086065\n",
      "\n",
      " Test set: Average loss: -1358,Accuracy:635814/656590 (77%)\n",
      "\n",
      "==============================\n",
      "\n",
      " Validation set: Average loss: -1356,Accuracy:166582/172788 (76%)\n",
      "\n",
      "==============================\n",
      "n = 172788\n",
      "True positives: 83861, True negatives: 82721, False positives: 3673, False negatives: 2533\n",
      "Actual no total: 86394, actual yes total: 86394\n",
      "Predicted no total: 85254, predicted yes total: 87534\n",
      "Precision: 0.9580391619256517, Recall: 0.970680834317198, F1 Score: 0.9643185686031002\n",
      "Train Epoch: 3 [1600248/2626360 (100%)]\tLoss: 0.099268\n",
      "\n",
      " Test set: Average loss: -1498,Accuracy:637484/656590 (97%)\n",
      "\n",
      "==============================\n",
      "\n",
      " Validation set: Average loss: -1494,Accuracy:167039/172788 (97%)\n",
      "\n",
      "==============================\n",
      "n = 172788\n",
      "True positives: 84151, True negatives: 82888, False positives: 3506, False negatives: 2243\n",
      "Actual no total: 86394, actual yes total: 86394\n",
      "Predicted no total: 85131, predicted yes total: 87657\n",
      "Precision: 0.9600031942685695, Recall: 0.9740375489038591, F1 Score: 0.9669694514826115\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    seed=42\n",
    "    EPOCHS=2 \n",
    "    \n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        train(model,device,train_dataloader,optimizer,epoch)\n",
    "        test(model,device,test_dataloader)\n",
    "        validation(model, device, valid_dataloader)\n",
    "        torch.save(model.state_dict(), constants.ALEXNETSAVE + f\"{epoch + 2}\" + \".pth\") # save model for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"zachnetfinal.pth\") # save final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('conv1.weight', tensor([[[-0.1301, -0.0414, -0.1000,  ...,  0.1285, -0.0584,  0.0390],\n",
      "         [-0.0343, -0.0470, -0.0336,  ...,  0.1267, -0.1360, -0.0865],\n",
      "         [-0.0023, -0.1100,  0.0172,  ...,  0.0850, -0.1270, -0.1141],\n",
      "         [-0.0009,  0.0879, -0.0347,  ...,  0.1460,  0.0240,  0.1367]],\n",
      "\n",
      "        [[-0.0524, -0.0461,  0.0385,  ..., -0.1278,  0.0421,  0.0551],\n",
      "         [-0.0746,  0.0903,  0.0191,  ..., -0.0905,  0.0104, -0.0546],\n",
      "         [ 0.1283,  0.1435,  0.0272,  ..., -0.0091, -0.1077,  0.0433],\n",
      "         [-0.0999,  0.0991,  0.0870,  ..., -0.0262,  0.1332,  0.0667]],\n",
      "\n",
      "        [[ 0.1063,  0.0370, -0.0834,  ..., -0.1467,  0.1038,  0.1239],\n",
      "         [-0.0427, -0.1389,  0.1516,  ...,  0.1308,  0.0983,  0.1401],\n",
      "         [ 0.0877,  0.1097, -0.0367,  ..., -0.1066, -0.1345,  0.0721],\n",
      "         [ 0.1320,  0.0412, -0.0722,  ..., -0.0639,  0.1087, -0.0815]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1315, -0.0685, -0.1925,  ...,  0.0684,  0.0901, -0.0424],\n",
      "         [ 0.0899,  0.0967,  0.0290,  ..., -0.0196,  0.0569, -0.1040],\n",
      "         [-0.1073, -0.1731, -0.1070,  ...,  0.0108,  0.0213, -0.0417],\n",
      "         [ 0.0467,  0.1055,  0.1618,  ..., -0.0405,  0.0527, -0.0441]],\n",
      "\n",
      "         [ 0.0760,  0.0233,  0.0481,  ...,  0.0908,  0.0289, -0.0436],\n",
      "         [[-0.0493, -0.1097,  0.1454,  ...,  0.0006,  0.0695,  0.0768],\n",
      "         [ 0.0454, -0.0718, -0.1539,  ..., -0.0994, -0.0491, -0.0694],\n",
      "         [ 0.0341,  0.0060,  0.0110,  ..., -0.0209,  0.0072,  0.1202]],\n",
      "\n",
      "        [[ 0.0323, -0.0877, -0.0382,  ...,  0.0774, -0.0572, -0.1054],\n",
      "         [-0.0160, -0.0693,  0.1499,  ..., -0.0968,  0.1219, -0.0911],\n",
      "         [ 0.1118,  0.0205,  0.1320,  ..., -0.1143, -0.0147,  0.1108],\n",
      "         [ 0.0343, -0.1536, -0.1702,  ..., -0.0401,  0.0789, -0.1631]]])), ('conv1.bias', tensor([ 0.0417, -0.0360,  0.0261, -0.0622,  0.0229,  0.0299,  0.1146, -0.1434,\n",
      "        -0.0249, -0.0912,  0.1099, -0.0248, -0.1094,  0.0526,  0.1124,  0.0850,\n",
      "         0.0861, -0.0866,  0.1167, -0.0098,  0.0159, -0.0577, -0.0232,  0.1264,\n",
      "         0.1455, -0.0356, -0.1062, -0.0145, -0.0891,  0.0601,  0.0135, -0.0833,\n",
      "         0.0084, -0.0042,  0.0685, -0.0392,  0.0474,  0.0129, -0.0241, -0.0053,\n",
      "         0.0034,  0.0652,  0.0271, -0.0037, -0.0984,  0.1225, -0.0589,  0.1400,\n",
      "        -0.1274,  0.0434, -0.1407, -0.1381,  0.0875, -0.0871,  0.1237, -0.0542,\n",
      "         0.0570, -0.0782,  0.0931,  0.1029, -0.1305,  0.0579, -0.0285, -0.0811])), ('conv2.weight', tensor([[[ 2.8026e-02,  2.7793e-02,  3.5395e-02,  ..., -3.7174e-02,\n",
      "          -3.4863e-02, -2.4046e-02],\n",
      "         [-1.1827e-02, -9.8263e-03, -1.5275e-02,  ...,  2.2327e-02,\n",
      "          -1.6140e-02, -2.3121e-02],\n",
      "         [-3.9678e-03, -1.1577e-02, -8.0992e-03,  ...,  2.0724e-03,\n",
      "          -1.5200e-02,  1.1064e-02],\n",
      "         ...,\n",
      "         [-6.0323e-02, -1.7131e-02,  2.1328e-02,  ..., -2.6866e-02,\n",
      "           1.0551e-02, -3.5811e-02],\n",
      "         [ 1.5924e-02, -1.4604e-02,  7.2798e-03,  ..., -1.0028e-02,\n",
      "          -4.4261e-02, -7.9715e-03],\n",
      "         [-4.0246e-02, -2.2460e-03, -5.9303e-02,  ...,  1.1139e-02,\n",
      "           7.1397e-02, -3.0826e-02]],\n",
      "\n",
      "        [[ 3.8088e-02,  2.9278e-02,  1.7389e-02,  ..., -1.7660e-02,\n",
      "          -2.0585e-02,  6.0626e-02],\n",
      "         [ 4.7321e-03,  1.5813e-02,  1.5601e-02,  ..., -2.0582e-03,\n",
      "           1.5068e-02, -3.8752e-03],\n",
      "         [ 1.4120e-02,  1.3872e-02,  3.5731e-02,  ...,  1.7042e-02,\n",
      "           2.1976e-02, -1.9318e-02],\n",
      "         ...,\n",
      "         [ 4.6194e-02, -3.6169e-02, -4.5105e-02,  ..., -3.3850e-02,\n",
      "           3.8705e-02,  2.8410e-02],\n",
      "         [ 1.7556e-02, -2.6630e-02, -6.0566e-02,  ...,  1.8899e-04,\n",
      "           3.3569e-02,  3.3284e-02],\n",
      "         [-1.8754e-02,  3.6666e-02, -6.7687e-03,  ..., -6.6778e-03,\n",
      "          -4.3929e-02,  1.9920e-03]],\n",
      "\n",
      "        [[ 3.2146e-02,  2.8485e-02,  2.0454e-02,  ...,  4.1737e-02,\n",
      "           4.3298e-02,  1.7994e-02],\n",
      "         [ 1.6604e-02, -3.3225e-02,  2.1184e-02,  ..., -4.1415e-02,\n",
      "           2.9551e-02, -2.4718e-02],\n",
      "         [ 2.2337e-02, -1.2909e-02, -2.3663e-02,  ..., -2.9076e-02,\n",
      "           4.1270e-02, -2.7934e-02],\n",
      "         ...,\n",
      "         [-1.3852e-03,  1.5176e-02,  5.5776e-02,  ..., -1.8095e-02,\n",
      "           4.4058e-02,  4.6415e-02],\n",
      "         [-5.8535e-03, -1.0419e-02, -5.3022e-03,  ...,  2.3080e-02,\n",
      "           2.8698e-02, -3.0220e-02],\n",
      "         [-1.5435e-02,  9.9989e-04,  4.5917e-03,  ...,  1.1659e-02,\n",
      "           1.5086e-02,  3.8114e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.0772e-02, -3.9949e-02, -2.6277e-02,  ...,  1.1308e-02,\n",
      "           1.6712e-02, -9.8827e-03],\n",
      "         [ 1.7841e-02, -3.4235e-03, -3.2436e-02,  ..., -2.0062e-02,\n",
      "          -2.4399e-02, -2.4140e-02],\n",
      "         [ 1.5952e-02,  2.2462e-02, -2.1390e-02,  ..., -5.3890e-03,\n",
      "           4.4568e-02, -1.5667e-02],\n",
      "         ...,\n",
      "         [ 2.2826e-02, -3.6460e-03,  2.0303e-02,  ...,  3.7099e-02,\n",
      "           1.5956e-02,  2.1235e-02],\n",
      "         [-3.4198e-02, -6.1593e-05,  6.7222e-03,  ..., -3.3936e-02,\n",
      "           3.9028e-03,  2.0524e-02],\n",
      "         [ 9.7704e-04, -2.3833e-03, -4.1065e-02,  ..., -1.1007e-03,\n",
      "           1.8024e-03,  1.8926e-02]],\n",
      "\n",
      "        [[ 1.1657e-02,  1.7664e-02, -2.3328e-02,  ..., -2.6785e-02,\n",
      "           1.9742e-02,  1.1653e-02],\n",
      "         [-3.6626e-02,  2.2539e-02,  2.3939e-02,  ...,  2.2556e-02,\n",
      "           2.8828e-02,  1.4219e-02],\n",
      "         [ 2.4877e-02, -2.9822e-02, -2.4670e-02,  ...,  2.2010e-02,\n",
      "          -2.9142e-02,  8.0699e-04],\n",
      "         ...,\n",
      "         [-7.5303e-03,  2.1867e-02,  1.9330e-02,  ...,  2.0883e-02,\n",
      "          -2.9357e-02,  7.3964e-02],\n",
      "         [-3.9553e-02,  1.2429e-03, -3.9461e-02,  ...,  9.1618e-03,\n",
      "           2.2655e-02,  2.4871e-02],\n",
      "         [-3.8733e-02,  4.1361e-02, -9.7955e-03,  ..., -2.7833e-02,\n",
      "          -5.0010e-02, -5.9980e-02]],\n",
      "\n",
      "        [[ 3.0125e-02, -7.3536e-03,  1.0144e-02,  ..., -2.7931e-03,\n",
      "           1.9508e-02,  2.7985e-02],\n",
      "         [-3.7686e-02,  1.8845e-02,  1.7050e-02,  ...,  2.1683e-03,\n",
      "           2.9644e-02, -3.9995e-02],\n",
      "         [ 3.6045e-02,  3.0659e-02, -1.4938e-02,  ..., -1.9594e-02,\n",
      "          -1.2987e-02,  4.2622e-02],\n",
      "         ...,\n",
      "         [-4.0920e-02, -7.1896e-03,  3.6430e-02,  ...,  2.8904e-02,\n",
      "           3.4122e-02,  2.0733e-02],\n",
      "         [ 4.7425e-03, -3.6527e-02,  1.7307e-02,  ...,  3.1258e-02,\n",
      "           1.6360e-02, -2.3060e-02],\n",
      "         [-6.9857e-02, -2.7470e-02,  2.2563e-02,  ...,  2.7000e-02,\n",
      "           1.4354e-03, -1.8820e-02]]])), ('conv2.bias', tensor([ 0.0204, -0.0281, -0.0330, -0.0373, -0.0375,  0.0062,  0.0198,  0.0175,\n",
      "         0.0155,  0.0310,  0.0271, -0.0229,  0.0086,  0.0217, -0.0240,  0.0089,\n",
      "        -0.0056, -0.0036, -0.0035, -0.0047, -0.0323, -0.0033,  0.0313,  0.0319,\n",
      "         0.0179, -0.0127,  0.0328, -0.0002,  0.0393, -0.0047,  0.0085,  0.0332,\n",
      "        -0.0162, -0.0225,  0.0212, -0.0298,  0.0298, -0.0334, -0.0012,  0.0061,\n",
      "         0.0018,  0.0361,  0.0302,  0.0097, -0.0168, -0.0187,  0.0028, -0.0278,\n",
      "         0.0227, -0.0261,  0.0235, -0.0034,  0.0089,  0.0366, -0.0047, -0.0168,\n",
      "         0.0103, -0.0418, -0.0139, -0.0136,  0.0341, -0.0133,  0.0125,  0.0119,\n",
      "         0.0324,  0.0264,  0.0378,  0.0193,  0.0030, -0.0066,  0.0151, -0.0104,\n",
      "         0.0289,  0.0016,  0.0343,  0.0234, -0.0273,  0.0395, -0.0016,  0.0344,\n",
      "         0.0356, -0.0164, -0.0012,  0.0390, -0.0340,  0.0063, -0.0214,  0.0125,\n",
      "        -0.0237, -0.0063,  0.0025, -0.0307, -0.0296,  0.0187,  0.0272, -0.0205])), ('conv3.weight', tensor([[[ 0.0035, -0.0173,  0.0481],\n",
      "         [ 0.0362, -0.0146, -0.0281],\n",
      "         [ 0.0168,  0.0136,  0.0277],\n",
      "         ...,\n",
      "         [ 0.0362,  0.0061,  0.0002],\n",
      "         [ 0.0173,  0.0410, -0.0657],\n",
      "         [-0.0370, -0.0074,  0.0594]],\n",
      "\n",
      "        [[-0.0239, -0.0246,  0.0386],\n",
      "         [ 0.0166, -0.0429, -0.0348],\n",
      "         [-0.0044, -0.0184, -0.0121],\n",
      "         ...,\n",
      "         [-0.0083,  0.0291,  0.0041],\n",
      "         [ 0.0030, -0.0110,  0.0250],\n",
      "         [ 0.0049,  0.0057, -0.0440]],\n",
      "\n",
      "        [[ 0.0641, -0.0304, -0.0005],\n",
      "         [ 0.0445, -0.0262,  0.0357],\n",
      "         [-0.0308,  0.0287,  0.0559],\n",
      "         ...,\n",
      "         [ 0.0393,  0.0147, -0.0437],\n",
      "         [-0.0425, -0.0521, -0.0194],\n",
      "         [ 0.0172,  0.0112,  0.0027]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0024, -0.0444,  0.0482],\n",
      "         [-0.0033,  0.0026,  0.0099],\n",
      "         [ 0.0004, -0.0237,  0.0454],\n",
      "         ...,\n",
      "         [ 0.0212,  0.0358,  0.0645],\n",
      "         [ 0.0308, -0.0363, -0.0198],\n",
      "         [ 0.0283,  0.0528, -0.0575]],\n",
      "\n",
      "        [[ 0.0401,  0.0558,  0.0467],\n",
      "         [ 0.0253,  0.0092,  0.0562],\n",
      "         [ 0.0069,  0.0305, -0.0178],\n",
      "         ...,\n",
      "         [ 0.0200, -0.0416,  0.0392],\n",
      "         [-0.0467,  0.0155, -0.0599],\n",
      "         [ 0.0509, -0.0196, -0.0515]],\n",
      "\n",
      "        [[-0.0507, -0.0365,  0.0064],\n",
      "         [-0.0543,  0.0204,  0.0144],\n",
      "         [ 0.0179,  0.0250,  0.0584],\n",
      "         ...,\n",
      "         [ 0.0154,  0.0601, -0.0522],\n",
      "         [-0.0041,  0.0329, -0.0176],\n",
      "         [-0.0143, -0.0171, -0.0596]]])), ('conv3.bias', tensor([ 0.0458, -0.0343, -0.0258, -0.0119, -0.0533, -0.0087, -0.0372, -0.0445,\n",
      "        -0.0386, -0.0195, -0.0237, -0.0303, -0.0295, -0.0471, -0.0203, -0.0499,\n",
      "         0.0370,  0.0124,  0.0481, -0.0492, -0.0028, -0.0182,  0.0417, -0.0558,\n",
      "        -0.0099,  0.0362, -0.0014, -0.0255, -0.0198,  0.0008, -0.0459,  0.0467,\n",
      "        -0.0541, -0.0226, -0.0420, -0.0087,  0.0156, -0.0362,  0.0017, -0.0418,\n",
      "         0.0376,  0.0565, -0.0339,  0.0362,  0.0174,  0.0196, -0.0162, -0.0162,\n",
      "        -0.0217, -0.0207,  0.0036, -0.0415,  0.0369, -0.0465, -0.0353,  0.0587,\n",
      "         0.0325,  0.0268, -0.0187, -0.0011,  0.0434, -0.0021, -0.0209,  0.0173,\n",
      "        -0.0483,  0.0236,  0.0010, -0.0542,  0.0410, -0.0570, -0.0343, -0.0334,\n",
      "         0.0023,  0.0392,  0.0252,  0.0073, -0.0538, -0.0070, -0.0285, -0.0474,\n",
      "         0.0024,  0.0612, -0.0054, -0.0534, -0.0431, -0.0364, -0.0292,  0.0043,\n",
      "         0.0242,  0.0338, -0.0297,  0.0279, -0.0128,  0.0505,  0.0136,  0.0068])), ('conv4.weight', tensor([[[ 2.2544e-02, -2.1908e-02,  2.7030e-02,  ..., -1.6648e-02,\n",
      "          -2.6203e-02,  8.4371e-03],\n",
      "         [-1.1852e-02,  2.0112e-02,  3.7927e-02,  ...,  8.0032e-03,\n",
      "          -1.7396e-02, -1.3691e-02],\n",
      "         [ 1.7114e-02,  3.1796e-02, -1.7637e-02,  ..., -3.5201e-02,\n",
      "          -3.8357e-02, -4.1213e-02],\n",
      "         ...,\n",
      "         [ 7.8761e-02,  4.2231e-02,  1.3507e-02,  ...,  5.0446e-02,\n",
      "           5.8720e-02,  8.8108e-02],\n",
      "         [-6.9288e-03, -1.1007e-02,  1.1220e-02,  ...,  1.1080e-02,\n",
      "          -1.2234e-02,  1.4048e-02],\n",
      "         [-2.5549e-02, -2.3631e-02,  1.1113e-02,  ..., -1.5080e-02,\n",
      "          -6.9428e-02, -3.3409e-02]],\n",
      "\n",
      "        [[-2.0280e-02, -1.2344e-02,  4.8307e-02,  ..., -2.4273e-02,\n",
      "           3.1722e-03,  1.0899e-02],\n",
      "         [ 1.7240e-02, -3.5908e-02, -3.6511e-02,  ..., -3.6099e-03,\n",
      "           1.2856e-02, -3.6612e-02],\n",
      "         [ 3.0365e-02, -2.0124e-02,  3.3554e-02,  ..., -4.7124e-03,\n",
      "           4.7731e-02, -5.8049e-04],\n",
      "         ...,\n",
      "         [-5.9982e-03, -1.4126e-02, -2.5165e-02,  ..., -1.6584e-02,\n",
      "           6.5677e-03,  6.2260e-03],\n",
      "         [ 6.6722e-02, -6.4616e-03,  2.3536e-02,  ...,  3.7428e-02,\n",
      "          -8.0578e-03, -5.3846e-03],\n",
      "         [ 1.2457e-02,  3.0178e-02,  3.6656e-02,  ...,  3.3726e-02,\n",
      "          -1.3509e-02,  1.3470e-02]],\n",
      "\n",
      "        [[ 2.8990e-02, -9.1087e-03,  5.1071e-02,  ..., -9.7551e-03,\n",
      "           4.0663e-02,  3.6741e-02],\n",
      "         [ 1.7029e-02, -2.3177e-02, -2.6541e-02,  ..., -9.0423e-04,\n",
      "          -1.4941e-02, -1.2938e-02],\n",
      "         [ 5.1286e-02,  2.3659e-02,  4.1899e-02,  ...,  1.0250e-02,\n",
      "          -2.1911e-02,  4.1344e-02],\n",
      "         ...,\n",
      "         [ 2.8538e-02, -2.7379e-02,  2.7722e-02,  ...,  1.4092e-02,\n",
      "           6.7040e-02,  1.5400e-02],\n",
      "         [ 6.8637e-02,  5.0724e-02,  3.3240e-02,  ..., -2.6944e-03,\n",
      "           4.6683e-02,  5.8213e-02],\n",
      "         [ 9.9792e-03, -2.5974e-03, -1.4608e-02,  ...,  3.2846e-02,\n",
      "           2.2679e-03, -9.6631e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.6702e-02,  3.1606e-02,  1.2985e-02,  ...,  5.0478e-02,\n",
      "           6.7482e-05,  4.7451e-02],\n",
      "         [-2.3639e-02, -2.8809e-03, -1.7945e-02,  ..., -3.7441e-02,\n",
      "           2.1036e-02, -1.3119e-02],\n",
      "         [ 5.3186e-02,  3.9795e-02,  4.6483e-04,  ...,  3.8657e-03,\n",
      "           5.5946e-02, -1.6506e-02],\n",
      "         ...,\n",
      "         [-2.0089e-02,  7.7407e-03,  1.8176e-02,  ...,  5.5665e-03,\n",
      "           7.3396e-03, -2.3408e-02],\n",
      "         [ 3.4048e-02,  4.2273e-02,  1.1146e-02,  ...,  6.5271e-02,\n",
      "           6.6501e-02,  3.3993e-02],\n",
      "         [ 4.2646e-02,  3.9288e-02,  1.9887e-02,  ...,  6.2129e-02,\n",
      "           9.6552e-03,  6.3215e-02]],\n",
      "\n",
      "        [[-2.0551e-02,  1.3582e-02, -1.9427e-02,  ...,  2.4902e-02,\n",
      "          -1.3705e-02,  2.1681e-03],\n",
      "         [-1.4228e-03,  3.6061e-02, -1.9978e-04,  ...,  1.4854e-02,\n",
      "          -2.9342e-02,  1.5702e-03],\n",
      "         [ 2.1373e-02, -9.2188e-03, -5.2106e-02,  ..., -1.4935e-02,\n",
      "          -4.1280e-03, -1.4287e-02],\n",
      "         ...,\n",
      "         [ 4.1480e-02,  7.5265e-02,  5.9058e-02,  ..., -1.0483e-02,\n",
      "           6.0900e-02,  4.0166e-04],\n",
      "         [-2.3496e-02,  2.4536e-02, -4.6427e-03,  ...,  1.7272e-02,\n",
      "           2.4521e-02, -1.6231e-02],\n",
      "         [-2.6241e-02, -5.9514e-03,  2.2148e-02,  ..., -4.7726e-02,\n",
      "          -7.4345e-03, -3.0631e-02]],\n",
      "\n",
      "        [[-1.3626e-02, -3.4472e-02, -2.1227e-02,  ..., -3.8816e-03,\n",
      "           3.2752e-03, -4.3526e-03],\n",
      "         [-7.7489e-03,  8.9153e-03, -2.1850e-02,  ..., -3.9174e-02,\n",
      "          -9.9093e-03,  2.5370e-02],\n",
      "         [ 1.1781e-02, -3.0088e-02,  1.7837e-02,  ...,  3.0719e-02,\n",
      "          -3.4330e-03,  4.9711e-03],\n",
      "         ...,\n",
      "         [-1.7117e-02, -2.5074e-02, -4.1692e-02,  ...,  2.3024e-02,\n",
      "           3.1408e-02, -3.7674e-02],\n",
      "         [-1.1732e-03, -6.7418e-02,  5.5817e-03,  ..., -1.0204e-03,\n",
      "           1.5642e-03,  3.8303e-02],\n",
      "         [-6.4653e-03, -2.9318e-02, -6.9689e-04,  ...,  2.3741e-02,\n",
      "          -1.1418e-02,  2.2182e-02]]])), ('conv4.bias', tensor([-0.0047,  0.0261,  0.0310,  0.0255,  0.0388,  0.0335,  0.0398, -0.0088,\n",
      "        -0.0188,  0.0044,  0.0185, -0.0094,  0.0383,  0.0447,  0.0204, -0.0319,\n",
      "        -0.0246,  0.0236, -0.0239,  0.0244,  0.0187,  0.0226,  0.0010,  0.0030,\n",
      "         0.0384,  0.0054, -0.0173, -0.0008,  0.0257,  0.0064, -0.0327, -0.0114,\n",
      "        -0.0185,  0.0421,  0.0172,  0.0116,  0.0141, -0.0299, -0.0264,  0.0002,\n",
      "         0.0117,  0.0093, -0.0225,  0.0221,  0.0138, -0.0270,  0.0162,  0.0159,\n",
      "         0.0301,  0.0079, -0.0192,  0.0170, -0.0209,  0.0117,  0.0165, -0.0189,\n",
      "        -0.0110,  0.0386,  0.0079, -0.0010, -0.0039, -0.0177, -0.0260, -0.0233,\n",
      "         0.0109,  0.0040,  0.0271, -0.0100,  0.0312, -0.0093,  0.0443, -0.0134,\n",
      "         0.0002,  0.0154,  0.0047,  0.0228, -0.0171,  0.0090,  0.0103,  0.0289,\n",
      "         0.0539,  0.0124,  0.0112,  0.0069,  0.0160,  0.0224,  0.0018,  0.0402,\n",
      "         0.0354,  0.0019, -0.0042,  0.0097, -0.0086,  0.0356,  0.0364,  0.0576])), ('conv5.weight', tensor([[[-0.0518],\n",
      "         [ 0.0067],\n",
      "         [-0.1213],\n",
      "         ...,\n",
      "         [ 0.0032],\n",
      "         [-0.0663],\n",
      "         [ 0.0335]],\n",
      "\n",
      "        [[ 0.0491],\n",
      "         [-0.0356],\n",
      "         [ 0.0396],\n",
      "         ...,\n",
      "         [ 0.0668],\n",
      "         [ 0.1160],\n",
      "         [-0.0974]],\n",
      "\n",
      "        [[ 0.0766],\n",
      "         [-0.0495],\n",
      "         [-0.0334],\n",
      "         ...,\n",
      "         [ 0.0657],\n",
      "         [-0.0706],\n",
      "         [ 0.0867]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0376],\n",
      "         [ 0.0910],\n",
      "         [ 0.0515],\n",
      "         ...,\n",
      "         [-0.0098],\n",
      "         [ 0.0528],\n",
      "         [-0.0545]],\n",
      "\n",
      "        [[ 0.0809],\n",
      "         [-0.0041],\n",
      "         [ 0.0160],\n",
      "         ...,\n",
      "         [ 0.0165],\n",
      "         [ 0.0514],\n",
      "         [-0.0744]],\n",
      "\n",
      "        [[-0.0307],\n",
      "         [ 0.0911],\n",
      "         [-0.0401],\n",
      "         ...,\n",
      "         [ 0.0668],\n",
      "         [-0.0172],\n",
      "         [ 0.0778]]])), ('conv5.bias', tensor([ 0.0415,  0.0574,  0.0756,  0.0624,  0.0834,  0.0101,  0.1059,  0.0756,\n",
      "         0.0725, -0.0118,  0.0262,  0.0641,  0.0109, -0.0995,  0.0429, -0.0051,\n",
      "        -0.0016, -0.0189, -0.0645,  0.0785,  0.0269,  0.0919,  0.0451,  0.0881,\n",
      "         0.0347,  0.0322, -0.0746, -0.0711,  0.0240,  0.0879, -0.0719, -0.0411,\n",
      "        -0.0678, -0.0260,  0.0758, -0.0052,  0.0948,  0.0352,  0.0926,  0.0045,\n",
      "         0.0395, -0.0024,  0.0250, -0.0066, -0.0357, -0.0008, -0.0010, -0.0110,\n",
      "         0.0304, -0.0388,  0.0728, -0.0152, -0.0178, -0.0848,  0.0318,  0.0727,\n",
      "         0.0552,  0.0863, -0.0537, -0.0066,  0.0164,  0.0751,  0.0822, -0.0138,\n",
      "        -0.0952,  0.0010,  0.0610,  0.0535, -0.0128, -0.0210,  0.0711,  0.0635,\n",
      "         0.0391, -0.0032, -0.0147,  0.0460, -0.0135,  0.0960,  0.0831,  0.0116,\n",
      "        -0.0860,  0.0452,  0.0505,  0.0434,  0.0361, -0.0458,  0.0549, -0.1016,\n",
      "        -0.0397,  0.0194,  0.0155, -0.0340, -0.0481,  0.0681, -0.0947,  0.0045])), ('conv6.weight', tensor([[[-0.0133],\n",
      "         [-0.0102],\n",
      "         [-0.0434],\n",
      "         ...,\n",
      "         [ 0.1205],\n",
      "         [ 0.0309],\n",
      "         [-0.1274]],\n",
      "\n",
      "        [[-0.0776],\n",
      "         [ 0.0528],\n",
      "         [ 0.0384],\n",
      "         ...,\n",
      "         [ 0.0937],\n",
      "         [ 0.0427],\n",
      "         [ 0.0555]],\n",
      "\n",
      "        [[ 0.0409],\n",
      "         [-0.0033],\n",
      "         [-0.1007],\n",
      "         ...,\n",
      "         [-0.0797],\n",
      "         [ 0.0883],\n",
      "         [-0.0331]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0722],\n",
      "         [ 0.0774],\n",
      "         [ 0.1034],\n",
      "         ...,\n",
      "         [ 0.0568],\n",
      "         [-0.0300],\n",
      "         [ 0.0882]],\n",
      "\n",
      "        [[ 0.0325],\n",
      "         [ 0.1109],\n",
      "         [-0.0420],\n",
      "         ...,\n",
      "         [ 0.0818],\n",
      "         [ 0.0816],\n",
      "         [-0.0276]],\n",
      "\n",
      "        [[-0.0652],\n",
      "         [-0.0906],\n",
      "         [-0.0502],\n",
      "         ...,\n",
      "         [ 0.0414],\n",
      "         [-0.0826],\n",
      "         [-0.0551]]])), ('conv6.bias', tensor([ 0.0485, -0.0098, -0.0360, -0.0028,  0.0354, -0.0536, -0.0750, -0.0485,\n",
      "         0.0014,  0.0115,  0.0317,  0.0373,  0.0605, -0.0880, -0.0864, -0.0905,\n",
      "         0.0203,  0.0199, -0.0002,  0.0459,  0.0473, -0.0900, -0.0076, -0.0013,\n",
      "        -0.0929,  0.0734, -0.0860, -0.0556, -0.0975, -0.0924,  0.0433,  0.0259,\n",
      "        -0.0447,  0.0400,  0.0276,  0.0707, -0.0055, -0.0366, -0.0461, -0.0194,\n",
      "        -0.0462, -0.0545, -0.0148,  0.0583,  0.0430, -0.0003, -0.0544,  0.0772,\n",
      "         0.0443, -0.0177,  0.0163, -0.0266,  0.0854,  0.0701,  0.0963, -0.0065,\n",
      "         0.0717, -0.0825, -0.0029,  0.0693, -0.0924, -0.0212,  0.0589, -0.0808,\n",
      "         0.0847, -0.0379,  0.0238, -0.0597, -0.0174, -0.0108,  0.0260, -0.0981,\n",
      "        -0.0131,  0.0448, -0.0255,  0.0533, -0.0998, -0.0821, -0.0369, -0.0072,\n",
      "         0.0225,  0.0217, -0.0745,  0.0222, -0.0660, -0.0481, -0.0611,  0.0175,\n",
      "         0.0369,  0.0565, -0.0059,  0.0757,  0.0151, -0.0515,  0.0567, -0.0981])), ('conv7.weight', tensor([[[-0.0403, -0.0363, -0.0016],\n",
      "         [-0.0256,  0.0115,  0.0789],\n",
      "         [-0.0614, -0.0255,  0.0107],\n",
      "         ...,\n",
      "         [ 0.0375,  0.0437, -0.0249],\n",
      "         [-0.0392,  0.0339,  0.0253],\n",
      "         [ 0.0395,  0.0565, -0.0459]],\n",
      "\n",
      "        [[ 0.0091,  0.0542, -0.0034],\n",
      "         [-0.0336, -0.0336,  0.0474],\n",
      "         [-0.0125,  0.0569, -0.1222],\n",
      "         ...,\n",
      "         [ 0.0338, -0.0236, -0.0125],\n",
      "         [ 0.0173, -0.0188,  0.0126],\n",
      "         [-0.0477, -0.0169, -0.0099]],\n",
      "\n",
      "        [[ 0.0484, -0.0575, -0.0178],\n",
      "         [ 0.0734,  0.0577,  0.0424],\n",
      "         [ 0.0344,  0.0278, -0.0300],\n",
      "         ...,\n",
      "         [ 0.0468, -0.0224,  0.0558],\n",
      "         [-0.0080, -0.0147, -0.0447],\n",
      "         [-0.0539, -0.0124,  0.0053]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0582,  0.0234,  0.0640],\n",
      "         [-0.0163,  0.0510,  0.0725],\n",
      "         [-0.0344,  0.0268,  0.0190],\n",
      "         ...,\n",
      "         [-0.0178,  0.0169,  0.0187],\n",
      "         [-0.0351, -0.0030, -0.0133],\n",
      "         [-0.0032, -0.0230, -0.0044]],\n",
      "\n",
      "        [[ 0.0211, -0.0009,  0.0126],\n",
      "         [ 0.0329,  0.0411, -0.0379],\n",
      "         [-0.0288, -0.0713,  0.0083],\n",
      "         ...,\n",
      "         [ 0.0402,  0.0251,  0.0237],\n",
      "         [ 0.0278,  0.0850,  0.0027],\n",
      "         [-0.0556, -0.0330,  0.0487]],\n",
      "\n",
      "        [[ 0.0670, -0.0684, -0.0493],\n",
      "         [ 0.0246,  0.0392,  0.0051],\n",
      "         [ 0.0364,  0.0618,  0.0672],\n",
      "         ...,\n",
      "         [ 0.0340, -0.0167, -0.0255],\n",
      "         [ 0.0180,  0.0307, -0.0346],\n",
      "         [ 0.0448,  0.0151,  0.0007]]])), ('conv7.bias', tensor([ 0.0627,  0.0058,  0.0515,  0.0122, -0.0387, -0.0306,  0.0595, -0.0381,\n",
      "        -0.0247, -0.0211, -0.0029, -0.0333,  0.0150,  0.0059,  0.0343,  0.0476,\n",
      "         0.0410, -0.0079, -0.0094, -0.0187,  0.0373,  0.0294,  0.0237,  0.0239,\n",
      "         0.0375,  0.0501,  0.0579,  0.0793,  0.0114,  0.0161, -0.0225,  0.0209,\n",
      "        -0.0196,  0.0686,  0.0584,  0.0178, -0.0379,  0.0388,  0.0494, -0.0508,\n",
      "        -0.0108, -0.0499,  0.0310,  0.0467,  0.0358,  0.0006, -0.0265, -0.0456,\n",
      "        -0.0190,  0.0606,  0.0211, -0.0099, -0.0287,  0.0438,  0.0028,  0.0590,\n",
      "         0.0276,  0.0415,  0.0717,  0.0453, -0.0276,  0.0352, -0.0327,  0.0184,\n",
      "         0.0145,  0.0428,  0.0172,  0.0055, -0.0106,  0.0657, -0.0415,  0.0165,\n",
      "         0.0255, -0.0047,  0.0560,  0.0275, -0.0365,  0.0729,  0.0318, -0.0480,\n",
      "         0.0247,  0.0415,  0.0377,  0.0382,  0.0035,  0.0024,  0.0258, -0.0447,\n",
      "         0.0138, -0.0223,  0.0204, -0.0573,  0.0431, -0.0024,  0.0546, -0.0388])), ('conv8.weight', tensor([[[ 0.0199],\n",
      "         [-0.0178],\n",
      "         [-0.0627],\n",
      "         ...,\n",
      "         [ 0.1041],\n",
      "         [-0.0187],\n",
      "         [-0.1077]],\n",
      "\n",
      "        [[ 0.0343],\n",
      "         [-0.0274],\n",
      "         [-0.0935],\n",
      "         ...,\n",
      "         [ 0.0311],\n",
      "         [ 0.0581],\n",
      "         [-0.0693]],\n",
      "\n",
      "        [[ 0.0950],\n",
      "         [-0.0498],\n",
      "         [ 0.0546],\n",
      "         ...,\n",
      "         [-0.0152],\n",
      "         [-0.0262],\n",
      "         [ 0.1028]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0006],\n",
      "         [-0.0753],\n",
      "         [-0.0015],\n",
      "         ...,\n",
      "         [ 0.0721],\n",
      "         [ 0.0806],\n",
      "         [ 0.0449]],\n",
      "\n",
      "        [[ 0.0763],\n",
      "         [ 0.0165],\n",
      "         [ 0.0837],\n",
      "         ...,\n",
      "         [ 0.0481],\n",
      "         [-0.0829],\n",
      "         [ 0.0704]],\n",
      "\n",
      "        [[-0.1055],\n",
      "         [-0.0900],\n",
      "         [ 0.0719],\n",
      "         ...,\n",
      "         [ 0.0912],\n",
      "         [ 0.0837],\n",
      "         [-0.0549]]])), ('conv8.bias', tensor([ 0.0657, -0.0694, -0.0165, -0.0962, -0.0671, -0.0171,  0.0225,  0.0507,\n",
      "         0.0942,  0.0817,  0.0064,  0.0914, -0.1002,  0.1058,  0.0882,  0.0230,\n",
      "        -0.0251, -0.0651, -0.0370, -0.0536, -0.0229, -0.0221,  0.0512,  0.0825,\n",
      "        -0.0128,  0.1061,  0.1079, -0.0766,  0.0635, -0.0289,  0.0506, -0.0191,\n",
      "        -0.0815, -0.0466,  0.0232,  0.0878,  0.0840,  0.0090,  0.0002, -0.0370,\n",
      "         0.0836, -0.0295, -0.0112, -0.0157,  0.0497, -0.0049,  0.0418, -0.0310,\n",
      "        -0.0332,  0.0929,  0.0638, -0.0034, -0.0276, -0.0149,  0.0565,  0.0362,\n",
      "        -0.0882, -0.0491,  0.0108,  0.0075,  0.0694, -0.0033, -0.0124,  0.0890,\n",
      "         0.1149, -0.0440,  0.0123, -0.0625,  0.0945, -0.0048,  0.0727, -0.0623,\n",
      "        -0.0896, -0.0431, -0.0088, -0.0508, -0.0033, -0.0858, -0.0200,  0.0902,\n",
      "         0.0733, -0.0208,  0.0593, -0.0877,  0.0322,  0.0071, -0.0281, -0.0083,\n",
      "        -0.0420,  0.0198,  0.0003,  0.0490, -0.0142, -0.0036, -0.0162, -0.0785])), ('conv9.weight', tensor([[[ 3.8995e-02, -3.0232e-02],\n",
      "         [-7.9749e-02,  1.6067e-02],\n",
      "         [ 7.6868e-02,  6.2947e-02],\n",
      "         ...,\n",
      "         [ 6.3593e-02,  1.0510e-02],\n",
      "         [ 1.0812e-02,  9.4765e-02],\n",
      "         [-1.9208e-02, -2.1741e-03]],\n",
      "\n",
      "        [[-5.5472e-02, -4.1207e-02],\n",
      "         [-5.0039e-02, -6.1871e-02],\n",
      "         [ 2.0942e-02, -9.6713e-03],\n",
      "         ...,\n",
      "         [-6.0577e-02, -5.9702e-02],\n",
      "         [ 3.3901e-02, -5.0402e-02],\n",
      "         [-2.3556e-02,  3.8316e-02]],\n",
      "\n",
      "        [[-1.4404e-02,  1.5946e-02],\n",
      "         [-7.9295e-02,  2.5287e-02],\n",
      "         [-4.4841e-02,  4.2573e-02],\n",
      "         ...,\n",
      "         [ 6.7512e-02, -1.3153e-02],\n",
      "         [-4.8041e-02,  1.0903e-02],\n",
      "         [ 5.5409e-02,  2.2073e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.5364e-05, -5.3700e-02],\n",
      "         [-3.3272e-02, -1.4714e-02],\n",
      "         [-2.4973e-02,  6.6220e-02],\n",
      "         ...,\n",
      "         [ 1.8163e-03, -4.5173e-02],\n",
      "         [ 6.5829e-02,  4.1677e-02],\n",
      "         [ 9.0043e-03,  4.8591e-02]],\n",
      "\n",
      "        [[-4.1919e-02, -1.3456e-02],\n",
      "         [ 4.9009e-02, -3.6890e-02],\n",
      "         [ 5.2346e-02,  6.0810e-02],\n",
      "         ...,\n",
      "         [ 5.9768e-02, -1.3522e-02],\n",
      "         [-6.2791e-03,  3.1498e-02],\n",
      "         [ 1.5206e-02, -3.5435e-02]],\n",
      "\n",
      "        [[ 6.4006e-02, -5.0747e-02],\n",
      "         [-6.2796e-02, -6.6909e-02],\n",
      "         [ 4.2619e-02, -9.9632e-03],\n",
      "         ...,\n",
      "         [ 2.5091e-02,  2.0611e-02],\n",
      "         [-8.1434e-03,  1.6058e-02],\n",
      "         [-2.9916e-02,  1.9547e-02]]])), ('conv9.bias', tensor([-2.3007e-02, -3.1235e-02, -5.1079e-02,  5.9377e-04, -1.0635e-02,\n",
      "        -3.8362e-02, -2.5673e-02, -5.6255e-02, -7.2581e-02,  4.2147e-02,\n",
      "         2.4331e-02, -3.0461e-02,  5.0851e-02,  1.7519e-02, -6.1132e-02,\n",
      "        -2.7331e-02, -2.2795e-02, -6.1620e-02, -3.1212e-02, -2.4891e-02,\n",
      "         3.8366e-02,  2.0452e-02, -5.4515e-02, -1.5145e-02, -4.0518e-02,\n",
      "         8.5893e-03, -4.2575e-02,  3.3483e-02,  5.4842e-02, -2.5154e-02,\n",
      "         2.6998e-02, -1.9863e-02, -4.0608e-02, -5.8803e-02, -6.2742e-02,\n",
      "        -1.3748e-03,  2.5667e-02,  3.3049e-02, -5.4419e-03,  3.0093e-02,\n",
      "         3.6074e-02,  4.0465e-02,  2.1532e-02,  5.3841e-02,  3.0740e-02,\n",
      "         7.0803e-03, -4.0140e-02,  4.3188e-02,  2.9472e-02, -5.0392e-02,\n",
      "        -1.3916e-02, -2.4324e-02, -3.7359e-02, -2.1305e-02,  5.2960e-02,\n",
      "        -6.5737e-02,  1.2362e-02,  3.3170e-02, -2.2725e-02,  2.7926e-02,\n",
      "        -9.1631e-03,  1.1426e-02,  4.9719e-02,  3.5836e-02, -2.8334e-02,\n",
      "         1.5589e-02,  1.7921e-02,  2.7502e-02,  5.1285e-02,  4.5787e-02,\n",
      "         4.0073e-02,  3.4359e-02, -5.7170e-02, -5.1697e-02,  5.0529e-05,\n",
      "        -4.8825e-02, -8.8591e-03,  1.2424e-02, -2.5926e-02,  3.6746e-02,\n",
      "         6.1997e-02, -1.8964e-02,  5.8280e-02,  1.4257e-02, -1.3289e-02,\n",
      "        -3.2473e-02, -2.6227e-02,  4.2660e-02, -3.7531e-03, -5.5031e-02,\n",
      "        -4.0764e-02, -5.3082e-02, -4.2595e-02,  1.1412e-02,  1.1895e-02,\n",
      "        -1.5758e-02])), ('fc1.weight', tensor([[-2.8593e-03, -4.3852e-02,  2.8886e-02,  ...,  3.2674e-03,\n",
      "          8.7533e-03,  1.9455e-02],\n",
      "        [-2.7806e-02,  3.3937e-02, -2.2762e-02,  ..., -1.8757e-02,\n",
      "         -1.6880e-02,  2.2480e-02],\n",
      "        [ 1.7739e-02,  1.5122e-02, -2.6711e-02,  ..., -1.6006e-02,\n",
      "         -2.1633e-02, -2.8144e-02],\n",
      "        ...,\n",
      "        [-2.5923e-02, -7.0391e-02,  6.1296e-05,  ..., -1.9632e-02,\n",
      "         -8.5756e-03,  3.4452e-02],\n",
      "        [ 2.8637e-02, -6.9600e-03,  1.0846e-02,  ..., -3.2329e-02,\n",
      "          2.6280e-02,  2.2635e-02],\n",
      "        [ 8.9113e-03,  1.0614e-03,  3.0353e-03,  ...,  3.5977e-02,\n",
      "          2.2351e-03, -3.9163e-03]])), ('fc1.bias', tensor([ 0.0054,  0.0276,  0.0174,  ...,  0.0388, -0.0158, -0.0124])), ('fc2.weight', tensor([[-0.0147, -0.0389,  0.0165,  ...,  0.0559, -0.0036, -0.0174],\n",
      "        [-0.0132, -0.0227, -0.0016,  ..., -0.0171,  0.0006,  0.0338],\n",
      "        [-0.0167,  0.0009, -0.0099,  ..., -0.0625, -0.0004, -0.0167],\n",
      "        ...,\n",
      "        [-0.0423, -0.0200, -0.0002,  ..., -0.0660,  0.0275,  0.0312],\n",
      "        [ 0.0011,  0.0038, -0.0320,  ...,  0.0065, -0.0295, -0.0261],\n",
      "        [ 0.0006, -0.0224, -0.0420,  ...,  0.0268, -0.0121,  0.0043]])), ('fc2.bias', tensor([-0.0080, -0.0051, -0.0324,  ...,  0.0199, -0.0144,  0.0163])), ('fc3.weight', tensor([[-0.0298,  0.0151,  0.0106,  ...,  0.0198,  0.0170, -0.0055],\n",
      "        [-0.0212, -0.0015, -0.0172,  ..., -0.0224,  0.0211,  0.0161]])), ('fc3.bias', tensor([0.0196, 0.0202]))])\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"zachnet.pth\")\n",
    "print(model)\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
